<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Insights</title><link href="http://eoinbrazil.com/" rel="alternate"></link><link href="http://eoinbrazil.com/feeds/all.atom.xml" rel="self"></link><id>http://eoinbrazil.com/</id><updated>2014-11-19T00:00:00+00:00</updated><entry><title>Research</title><link href="http://eoinbrazil.com/my-research.html" rel="alternate"></link><updated>2014-11-19T00:00:00+00:00</updated><author><name>Eoin Brazil</name></author><id>tag:eoinbrazil.com,2014-11-19:my-research.html</id><summary type="html">&lt;p&gt;It&amp;#8217;s been a hectic few months learning the ins and outs of MongoDB. I&amp;#8217;ve learnt a lot but a request or two has made me realise that I&amp;#8217;d forgotten to bring a few artefacts from my past along with me and that the Internet has forgotten them. Over the years the links to my various disserations and theses have fallen out of circulation due to replacement of webservers and general spring cleaning of former researcher group&amp;nbsp;members.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m posting them back to this website and apologies to those who in the research community couldn&amp;#8217;t access them, I honestly hadn&amp;#8217;t realise they were not still been&amp;nbsp;hosted.&lt;/p&gt;
&lt;p&gt;My Masters thesis investigated sound / music collection management from the view point of browsing coupled with multiple visualisations and filtering. The question asked sought to discover if supporting a different form of navigating these resource might enhance the serendipity of the experience. Looking at it today, it is still an open question as whilst Spotify and similar streaming music services provide a search inspired navigation approach, there is still no browse inspired approach that allows you to be lost in oceans of sound and yet made those serendipitous discoveries.
&lt;span class="caps"&gt;PDF&lt;/span&gt;&amp;nbsp;version&lt;/p&gt;
&lt;p&gt;My PhD thesis investigated everyday sounds, specifically how people categorised these sounds and what meanings they associated with them. My work gathered a range of existing techniques from interaction design and from other domains to dig down to elict the multiple meanings that people assoicate with these sounds. The thesis provided a framework and guidance on how to map these meanings to usable categories. My eventual and still unreached goal was to design auditory interfaces using these sounds for public spaces where the sounds would have a communal meaning and a hidden/deeper personal meaning. The very essence of private communication with non-speech sounds in public environments where hidden messages could be passed to the listener due to the deeper understanding of how they would perceive the multiple layers of meaning inherent in the sound.
&lt;span class="caps"&gt;PDF&lt;/span&gt;&amp;nbsp;version&lt;/p&gt;
&lt;p&gt;My PGDip dissertation in technology commercialisation investigated how road mapping when combined with financial modeling in the context of data management. It provided an approach for businesses that allowes for the development of a technology strategy with clearly outlined cost benefits to the business. Road maps, particular technology road maps are a common tool in &lt;span class="caps"&gt;IT&lt;/span&gt; product management mid to long term strategies, however these do not include any clear financial modeling that allows tangible estimates to be developed and matched to the road map. I had worked with a number of companies in the cloud and high-performance computing space during this period and felt the cloud hype (which unfortunately still exists today) needed better tools for senior &lt;span class="caps"&gt;IT&lt;/span&gt; managers to both understand and justify their technology strategy choices.
&lt;span class="caps"&gt;PDF&lt;/span&gt;&amp;nbsp;version&lt;/p&gt;</summary></entry><entry><title>About</title><link href="http://eoinbrazil.com/about-me.html" rel="alternate"></link><updated>2013-11-12T00:00:00+00:00</updated><author><name>Eoin Brazil</name></author><id>tag:eoinbrazil.com,2013-11-12:about-me.html</id><summary type="html">&lt;p&gt;I&amp;#8217;m a technology guy with a background in &lt;span class="caps"&gt;UX&lt;/span&gt;, computer science and technology commercialisation. I&amp;#8217;ve spent several years working bringing research to commercialisation and managing consultancy projects with companies in Ireland and the&amp;nbsp;&lt;span class="caps"&gt;USA&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;I love science, technology, craft beer, whisky and&amp;nbsp;statistics.&lt;/p&gt;</summary></entry><entry><title>Handy Interaction Design - DEFUSE Dublin 2013</title><link href="http://eoinbrazil.com/handyinteractiondesign.html" rel="alternate"></link><updated>2013-11-11T00:00:00+00:00</updated><author><name>Eoin Brazil</name></author><id>tag:eoinbrazil.com,2013-11-11:handyinteractiondesign.html</id><summary type="html">&lt;p&gt;I was fortunate to have been asked to present at &lt;a href="http://www.ixd.ie/"&gt;IxDA Dublin&lt;/a&gt; &lt;a href="http://www.defuse.ixd.ie/"&gt;Design for Use 2013 (&lt;span class="caps"&gt;DEFUSE&lt;/span&gt;) conference&lt;/a&gt; on interaction design. I&amp;#8217;ll briefly walk through my talk in this post as technical issues on the night left it a little disjointed. I&amp;#8217;ve included references used in the talk for those interested in diving a little deeper into the topics I&amp;nbsp;covered.&lt;/p&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;p&gt;The talk was aimed at introducing persuasive design as one approach to dealing with the growth of mobile applications and beyond, particularly the increasing ubiquity of devices as illustrated by the Internet of&amp;nbsp;Things.&lt;/p&gt;
&lt;h4&gt;Slides 1 - 3: Our senses and humans as multimodal&amp;nbsp;creatures&lt;/h4&gt;
&lt;p&gt;&lt;script async class="speakerdeck-embed" data-slide="2" data-id="6b3c33302cf80131ff12122461a0ee5c" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="quo"&gt;&amp;#8216;&lt;/span&gt;Cortex&amp;#8217; man illustrates the amount of wiring in our brain that is dedicated to specific modalities. It highlights that we are multimodal creatures. In the past I&amp;#8217;ve worked on a range of alternative interfaces including buttons that you can hear but cannot see. In a world of increasing ubiquity of technology we need to re-imagine how we interact&amp;nbsp;technology.&lt;/p&gt;
&lt;p&gt;Reference:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="caps"&gt;IEEE&lt;/span&gt; Multimedia 2005, &lt;a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1423932"&gt;&lt;span class="caps"&gt;HCI&lt;/span&gt; Design and Interactive Sonification for Fingers and Ear&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Slides 4 - 7: From desktop to motes and the growth of mobile apps to the Internet of&amp;nbsp;Things&lt;/h4&gt;
&lt;p&gt;&lt;script async class="speakerdeck-embed" data-slide="4" data-id="6b3c33302cf80131ff12122461a0ee5c" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Jumping to the thoughts of Scott Jenson and the realisation that we simply cannot create an interface or application for every piece of technology as we move from the desktop, to dedicated devices, to motes or invisible technology. The growth of the Internet of Things will drown in us in a cacophony of machine voice, all of which are seeking our most limited resource that of our&amp;nbsp;attention.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://mobile.smashingmagazine.com/2013/10/08/responsive-website-design-with-ress/"&gt;Responsive design with server side components&lt;/a&gt; and multi-device design all attempt a technological solution focusing on presentation or hardware issues. These are only part of the problem, interaction requires much more than just a technical&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;Devices such as &lt;a href="http://www.google.com/glass/start/what-it-does/"&gt;Google&amp;#8217;s Glass&lt;/a&gt; or wearable ambient displays such as the &lt;a href="http://jorgeandesther.com/lume/"&gt;Lume&lt;/a&gt; show how we are only scratching the surface of what these devices can tell us about their usage, location and&amp;nbsp;context.&lt;/p&gt;
&lt;p&gt;Reference:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blog entry by Scott Jenson - August 1, 2012 &lt;a href="http://designmind.frogdesign.com/blog/of-bears-bats-and-bees-making-sense-of-the-internet-of-things.html"&gt;Of Bears, Bats, and Bees: Making Sense of the Internet of Things&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Slides 8 - 10: Emerging scenarios and contexts of use, device awareness of environment and responsive design/multi-device&amp;nbsp;design&lt;/h4&gt;
&lt;p&gt;&lt;script async class="speakerdeck-embed" data-slide="8" data-id="6b3c33302cf80131ff12122461a0ee5c" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Studies are showing us how people are using devices to tackle in a variety of ways that we are only beginning to design for and understand. Google&amp;#8217;s study on &lt;a href="http://www.google.com/think/research-studies/the-new-multi-screen-world-study.html"&gt;multi-device use for a variety of scenarios&lt;/a&gt; highlights how we need to re-consider interactions not just in terms of devices but also with regard to the relatedness of the activity and&amp;nbsp;behavior.&lt;/p&gt;
&lt;p&gt;Developments on the technology side such as environmental awareness via Device APIs that allow devices to provide more information about their context of use can help and provide guidance on whether it is appropriate  to interact with the person. Testing and querying what a device can do will still be part of a solution but we also need to focus on behaviors, mental models and the abilities of people in designing new interactions for ubiquitous&amp;nbsp;technology.&lt;/p&gt;
&lt;p&gt;References: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google August 2012, &lt;a href="http://www.google.com/think/research-studies/the-new-multi-screen-world-study.html"&gt;Research Study - The New Multi-Screen World Study&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Tim Wright, February 12 - 2013, A List Apart, &lt;a href="http://alistapart.com/article/environmental-design-with-the-device-api"&gt;&amp;#8220;Environmental Design with the Device &lt;span class="caps"&gt;API&lt;/span&gt;&amp;#8221;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Slide 11: A cavet, the difficulties of understanding and eliciting views of how people perceive the&amp;nbsp;world&lt;/h4&gt;
&lt;p&gt;&lt;script async class="speakerdeck-embed" data-slide="11" data-id="6b3c33302cf80131ff12122461a0ee5c" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Understanding and eliciting the views and contexts of how people perceive the world is &lt;bold&gt;difficult&lt;/bold&gt; and in this talk I only touch on a few approaches but there are many more that can&amp;nbsp;help.&lt;/p&gt;
&lt;h4&gt;Slide 12: - Moving beyond the traditional interface&amp;nbsp;paradigms&lt;/h4&gt;
&lt;p&gt;&lt;script async class="speakerdeck-embed" data-slide="12" data-id="6b3c33302cf80131ff12122461a0ee5c" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;We need to move beyond the command line and graphical user interface paradigms and really start to explore new paradigms such as the &lt;a href="http://en.wikipedia.org/wiki/Natural_user_interface"&gt;natural user interfaces&lt;/a&gt; with the likes of &lt;a href="http://www.microsoft.com/surface/en-ie"&gt;Microsoft&amp;#8217;s Surface&lt;/a&gt; and other tangible&amp;nbsp;interfaces.&lt;/p&gt;
&lt;h4&gt;Slides 13 - 18: Using models and approaches such as persuasive design to deal with attention and the clamouring noise from machines, services and applications competiting for&amp;nbsp;attention&lt;/h4&gt;
&lt;p&gt;&lt;script async class="speakerdeck-embed" data-slide="13" data-id="6b3c33302cf80131ff12122461a0ee5c" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;In tandem, we need to better model people&amp;#8217;s behaviors using the likes of &lt;a href="www.behaviormodel.org"&gt;&lt;span class="caps"&gt;BJ&lt;/span&gt; Fogg&amp;#8217;s model&lt;/a&gt; which captures motivation, ability, and triggers. It looks at not just a single interaction but right up to changing or habituating&amp;nbsp;behaviors.&lt;/p&gt;
&lt;p&gt;Does this type of approach work ? Mike Krieger is a former student of &lt;span class="caps"&gt;BJ&lt;/span&gt; Fogg and co-founded Instagram. He uses &lt;a href="http://www.forbes.com/sites/anthonykosner/2012/12/01/instagram-will-monetize-for-facebook-by-testing-solutions-one-week-at-a-time/"&gt;these approaches&lt;/a&gt; to decide what the new features will be included in&amp;nbsp;Instagram.&lt;/p&gt;
&lt;p&gt;Fogg has another paper on &lt;a href="http://link.springer.com/chapter/10.1007/978-3-540-68504-3_3"&gt;&amp;#8216;Mass Interpersonal Persuasion: An Early View of a New Phenomenon&amp;#8217;&lt;/a&gt; which looks at Facebook and the psychology of persuasion. It isn&amp;#8217;t exactly about creating a viral adoption model but it is a way of understanding how to reach and influence millions of people using this type of&amp;nbsp;technology.&lt;/p&gt;
&lt;p&gt;There are other models such as &lt;a href="http://en.wikipedia.org/wiki/Maslow's_hierarchy_of_needs"&gt;Maslow&amp;#8217;s hierarchy of needs&lt;/a&gt; but my message in this talk is that we need to consider designing for behaviors using psychology and persuasion to create experiences. It is not just about the&amp;nbsp;technology.&lt;/p&gt;
&lt;p&gt;In a world with an increasing ubiquity of technology we are seeing more and more machines designed to persuade. We need to look to these types of approaches or we&amp;#8217;re going to drown in a sea of&amp;nbsp;noise.&lt;/p&gt;
&lt;p&gt;References:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;International Conference on Persuasive Technology (Persuasive &amp;#8216;09), &lt;a href="http://dl.acm.org/citation.cfm?id=1541999"&gt;A behavior model for persuasive design&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Persuasive Technology, Lecture Notes in Computer Science Volume 5033, 2008, &lt;a href="http://link.springer.com/chapter/10.1007/978-3-540-68504-3_3"&gt;Mass Interpersonal Persuasion: An Early View of a New Phenomenon&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Psychological Review, 50, 370-396, 1943, &lt;a href="http://psychclassics.yorku.ca/Maslow/motivation.htm"&gt;A theory of human motivation&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Slide 19: Discovery and orchestration - the missing glue for seamless immediate&amp;nbsp;interaction&lt;/h4&gt;
&lt;p&gt;&lt;script async class="speakerdeck-embed" data-slide="19" data-id="6b3c33302cf80131ff12122461a0ee5c" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;I think that the next killer technology for mobile and for ubiquitous technology will be in discovery and orchestration. We need a solution to provide the platform to build seamless immediate interactions within a host of clamoring&amp;nbsp;voices.&lt;/p&gt;
&lt;h4&gt;Slide 20: Don&amp;#8217;t&amp;nbsp;Panic&lt;/h4&gt;
&lt;p&gt;&lt;script async class="speakerdeck-embed" data-slide="20" data-id="6b3c33302cf80131ff12122461a0ee5c" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;To quote Douglas Adams &amp;#8220;Don&amp;#8217;t Panic&amp;#8221;, there are approaches to addressing ubiquitous and mobile technology. We simply need to move beyond the traditional&amp;nbsp;toolkit.&lt;/p&gt;</summary><category term="defuse"></category><category term="design"></category><category term="ux"></category><category term="ixda"></category><category term="mobile"></category><category term="internet of things"></category><category term="persuasive design"></category><category term="ubiquitous technology"></category></entry><entry><title>Omnigraffle, Climacons and Font Awesome</title><link href="http://eoinbrazil.com/omnigrafflestencilforfonts.html" rel="alternate"></link><updated>2013-10-30T00:00:00+00:00</updated><author><name>Eoin Brazil</name></author><id>tag:eoinbrazil.com,2013-10-30:omnigrafflestencilforfonts.html</id><summary type="html">&lt;p&gt;I recently been doing a few sketches using &lt;a href="http://www.omnigroup.com/products/omnigraffle/"&gt;Omnigraffle&lt;/a&gt; and realised that I had to create my first stencils to support the graphical prototyping I&amp;#8217;d been working on. The first font is the excellent &lt;a href="http://fortawesome.github.io/Font-Awesome/"&gt;Font Awesome&lt;/a&gt; and it already had a great stencil from &lt;a href="http://www.patcheung.com/2013/06/font-awesome-omnigraffle-stencil-project/"&gt;Pat Cheung&lt;/a&gt; that I merely needed to update from his &lt;a href="patcheung/Font-Awesome-OmniGraffle-Stencil"&gt;version&lt;/a&gt; to include the latest release of the font. The second font was a really nice climate icon font, &lt;a href="http://adamwhitcroft.com/climacons/font/"&gt;Climacons&lt;/a&gt; that did not have any&amp;nbsp;stencil.&lt;/p&gt;
&lt;p&gt;I really took some inspiration from Pat&amp;#8217;s work and have sent a pull request back to his Github so hopefully the stencil will be updated. I really think that Dave Gandy and all the Font Awesome contributors have really created something so useful for wire&amp;nbsp;framing.&lt;/p&gt;
&lt;h3&gt;Font Awesome&amp;nbsp;Stencil&lt;/h3&gt;
&lt;p&gt;Firstly, down load the system font file from the &lt;a href="http://fortawesome.github.io"&gt;project&amp;#8217;s website&lt;/a&gt; and then install this font on your computer. You can then download the stencil from my (Github project)[https://github.com/braz/Font-Awesome-OmniGraffle-Stencil], double click the stencil file to install it. The links for these&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Font Awesome: &lt;a href="http://fontawesome.io"&gt;http://fontawesome.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Font Awesome 4.0.1 OmniGraffle Stencil github: &lt;a href="https://github.com/braz/Font-Awesome-OmniGraffle-Stencil"&gt;https://github.com/braz/Font-Awesome-OmniGraffle-Stencil&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Climacons&amp;nbsp;Stencil&lt;/h3&gt;
&lt;p&gt;Firstly, down load the system font file from the &lt;a href="http://adamwhitcroft.com/climacons/font/"&gt;project&amp;#8217;s website&lt;/a&gt; or the &lt;a href="https://github.com/AdamWhitcroft/Climacons"&gt;Github repository&lt;/a&gt; and then install this font on your computer. You can then download the stencil from my (Github project)[https://github.com/braz/climacons-omnigraffle-stencil]], double click the stencil file to install it. The links for these&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Climacons font: &lt;a href="http://adamwhitcroft.com/climacons/font/"&gt;http://adamwhitcroft.com/climacons/font/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Climacons github: &lt;a href="https://github.com/AdamWhitcroft/Climacons"&gt;https://github.com/AdamWhitcroft/Climacons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Climacons Omnigraffle Stencil github: &lt;a href="https://github.com/braz/climacons-omnigraffle-stencil"&gt;https://github.com/braz/climacons-omnigraffle-stencil&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hope you find these of use and feel free to submit pull requests as I intend to try and keep these&amp;nbsp;updated.&lt;/p&gt;</summary><category term="omnigraffle"></category><category term="fonts"></category><category term="stencils"></category><category term="design"></category></entry><entry><title>Introduction to Machine Learning with R</title><link href="http://eoinbrazil.com/introtomlwithr.html" rel="alternate"></link><updated>2013-10-08T00:00:00+01:00</updated><author><name>Eoin Brazil</name></author><id>tag:eoinbrazil.com,2013-10-08:introtomlwithr.html</id><summary type="html">&lt;p&gt;I had the pleasure of presenting to the &lt;a href="www.meetup.com/DublinR/"&gt;Dublin R User Group&lt;/a&gt; on machine learning. My talk source and examples are in a &lt;a href="https://github.com/braz/DublinR-ML-treesandforests/"&gt;Github repo&lt;/a&gt;. The talk was aimed at introducing machine learning to the group as I hope to follow this talk up with more intermediate&amp;nbsp;topics.&lt;/p&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;p&gt;The techniques covered&amp;nbsp;included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data&amp;nbsp;transformation&lt;/li&gt;
&lt;li&gt;Model&amp;nbsp;building&lt;/li&gt;
&lt;li&gt;Model assessment and&amp;nbsp;selection&lt;/li&gt;
&lt;li&gt;Interpreting a confusion&amp;nbsp;matrix&lt;/li&gt;
&lt;li&gt;Interpreting a &lt;span class="caps"&gt;ROC&lt;/span&gt;&amp;nbsp;plot&lt;/li&gt;
&lt;li&gt;Approaches to handling prediction&amp;nbsp;errors&lt;/li&gt;
&lt;li&gt;Addressing feature&amp;nbsp;selection&lt;/li&gt;
&lt;li&gt;Kaggle and data science&amp;nbsp;competitions&lt;/li&gt;
&lt;li&gt;A review of various &lt;span class="caps"&gt;ML&lt;/span&gt; techniques:&lt;ul&gt;
&lt;li&gt;Associate&amp;nbsp;rules&lt;/li&gt;
&lt;li&gt;Decision&amp;nbsp;trees&lt;/li&gt;
&lt;li&gt;Random&amp;nbsp;forests&lt;/li&gt;
&lt;li&gt;k Nearest&amp;nbsp;Neighbors&lt;/li&gt;
&lt;li&gt;Neural&amp;nbsp;networks&lt;/li&gt;
&lt;li&gt;Support vector&amp;nbsp;machines&lt;/li&gt;
&lt;li&gt;Naive&amp;nbsp;bayesian&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OpenRefine and&amp;nbsp;Rattle&lt;/li&gt;
&lt;li&gt;Useful command line tools for a data&amp;nbsp;scientist&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Background&lt;/h3&gt;
&lt;p&gt;The classification of objects into groups is a everyday task for humans and this talk helps highlight how to develop models to allow machines to do these tasks. The talk provide a quick understanding of machine learning algorithms showing how they worked, so that people would know when and how to best apply them. Machine learning and particularly feature generation for those models is seen as a &amp;#8220;black art&amp;#8221; due to the fact that domain expertise is required. The talk was aimed at showing people how R can be used in the process of selecting, assessing and creating models. It gave four datasets to show examples of exploratory data&amp;nbsp;analysis.&lt;/p&gt;
&lt;h3&gt;Talk&amp;nbsp;slides&lt;/h3&gt;
&lt;script async class="speakerdeck-embed" data-id="2cd19ca020bf0131063f72abddee51e1" data-ratio="1.41436464088398" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;</summary><category term="r"></category><category term="presentations"></category><category term="machine learning"></category><category term="rstats"></category></entry></feed>