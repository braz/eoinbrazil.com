<!doctype html><meta charset=utf-8><title>Insights</title><meta content=width=device-width,initial-scale=1.0 name=viewport><link href=http://eoinbrazil.com/theme/css/bootstrap.css media=screen rel=stylesheet><link href=http://eoinbrazil.com/theme/css/bootstrap-responsive.css media=screen rel=stylesheet><link href=http://eoinbrazil.com/theme/css/github.css media=screen rel=stylesheet><link href=http://eoinbrazil.com/theme/css/github-numbers.css media=screen rel=stylesheet><link href=http://eoinbrazil.com/theme/css/styles.css media=screen rel=stylesheet><link href=http://fonts.googleapis.com/css?family=Bitter:400,700 rel=stylesheet><link href=http://fonts.googleapis.com/css?family=Cantora+One rel=stylesheet><script type=speculationrules>
        {
          "prerender": [
            {
              "where": { "href_matches": "/*" },
              "eagerness": "moderate"
            }
          ],
          "prefetch": [
            {
              "where": { "not": { "href_matches": "/*" } },
              "eagerness": "moderate"
            }
          ]
        }
    </script><link title="Insights Atom Feed" href=http://eoinbrazil.com/feeds/all.atom.xml rel=alternate type=application/atom+xml><link title="Insights RSS Feed" href=http://eoinbrazil.com/feeds/all.rss.xml rel=alternate type=application/rss+xml><script>var _gaq=_gaq||[];_gaq.push([`_setAccount`,`UA-45182755-1`]);_gaq.push([`_trackPageview`]);(()=>{let c=`script`;var a=document.createElement(c);a.type=`text/javascript`;a.async=!0;a.src=(`https:`==document.location.protocol?`https://ssl`:`http://www`)+ `.google-analytics.com/ga.js`;var b=document.getElementsByTagName(c)[0];b.parentNode.insertBefore(a,b)})()</script><link href=http://eoinbrazil.com/celerydatabasebottlenecks.html rel=canonical><script type=application/ld+json>{"@context": "https://schema.org", "@type": "BreadcrumbList", "itemListElement": [{"@type": "ListItem", "position": 1, "name": "Insights", "item": "http://eoinbrazil.com"}, {"@type": "ListItem", "position": 2, "name": "Celerydatabasebottlenecks", "item": "http://eoinbrazil.com/celerydatabasebottlenecks.html"}]}</script><script type=application/ld+json>{"@context": "https://schema.org", "@type": "Article", "author": {"@type": "Person", "name": "Eoin Brazil"}, "publisher": {"@type": "Organization", "name": "Insights"}, "headline": "Celery Database&nbsp;Bottlenecks", "about": "Blog/Python", "datePublished": "2018-03-31 00:00"}</script><body><div class=miniBio><div class=container><a class=brand href=/ title=Insights><img src=http://eoinbrazil.com/img/avatar.png></a><span class=miniBioText>Creating ideas and insights.</span></div></div><div class=container><div class=container><div class=row><div class="span12 articleDetailHeadline"><h1>Celery Database Bottlenecks</h1><h2>The joys of performance whack-a-mole with distributed systems</h2></div></div></div><div class=container><div class="row articleDetail"><div class="span3 articleInfo light"><p><i class=icon-calendar></i> Sat 31 Mar 2018<p class=articleTags><i class=icon-tag></i> tags: <a href=http://eoinbrazil.com/tag/python.html>python</a> <a href=http://eoinbrazil.com/tag/queues.html>queues</a> <a href=http://eoinbrazil.com/tag/celery.html>celery</a> <a href=http://eoinbrazil.com/tag/bottlenecks.html>bottlenecks</a></div><div class="span6 articleDetailContent"><p>I recently had to refactor some code which uses MongoDB and Celery to store results from a scraping process to a MongoDB collection. It involved a number of whack a mole type performance problems due to the distributed nature of the system, and indeed was leading to the <a href=https://linux-mm.org/OOM_Killer>Linux out of memory (<span class=caps>OOM</span>) killer</a> being triggered against some of those workers. I wanted to write up some of the approaches I took as they may be helpful to others and indeed maybe there are better ways out there to handle the same situation (so any feedback would be much appreciated!).<p>The inspiration for writing this approach in a blog was another <a href=https://www.vinta.com.br/blog/2018/dealing-resource-consuming-tasks-celery/>blog post on handling memory intensive Celery workers</a>. This highlighted yet another Celery setting I wasn’t using on <a href=http://docs.celeryproject.org/en/latest/userguide/optimizing.html#prefetch-limits>prefetch limits</a> or indeed aware of. The approach from that blog used Celery’s worker prefetch limiting to avoid running out of memory on the workers. The approach below was what I used to avoid running out of memory. It occurs at one step earlier by avoiding sending tasks to the Celery worker from the Python programme distributing the work than throttling the tasks once on the workers. I think either approach may work and I’m glad to have found the blog to both prompt future thinking and my writing of this post.<h2>1. Limit task submission if Database queue is at or above the maximum threshold</h2><p>This function implemented a simple limit and wait logic for the application calling the specific Celery Workers, the example below uses a trivialised example with a single Worker named ‘celery1’. The Celery task inspection function, celery.task.control.inspect(), is queried in the calling Python programme and the running-threads value for the specific worker (which is only used for this one queue) is what determines whether this function will return. If there are too many existing tasks on the worker, the function will sleep until the number of tasks are less than the value set for the variable, message_queue_max.<div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span></pre></div><td class=code><div><pre><span></span><code><span class=k>def</span> <span class=nf>check_and_backoff_if_db_queue_at_max</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
<span class=n>message_queue_max</span> <span class=o>=</span> <span class=mi>15</span>
<span class=n>ins</span> <span class=o>=</span> <span class=n>inspect</span><span class=p>()</span>
<span class=k>try</span><span class=p>:</span>
    <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
        <span class=n>queue_over_max_length_for_worker_1</span> <span class=o>=</span> <span class=kc>False</span>
        <span class=n>all_stats</span> <span class=o>=</span> <span class=n>ins</span><span class=o>.</span><span class=n>stats</span><span class=p>()</span>
        <span class=k>if</span> <span class=n>all_stats</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>msg</span> <span class=o>=</span> <span class=s2>"No Celery Workers have been detected."</span>
            <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=n>msg</span><span class=p>)</span>
            <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=n>msg</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>all_stats</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
            <span class=k>if</span> <span class=n>k</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s1>'celery1'</span><span class=p>)</span> <span class=ow>and</span> <span class=n>all_stats</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=s1>'pool'</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>'running-threads'</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span> <span class=o>>=</span> <span class=n>message_queue_max</span><span class=p>:</span>
                <span class=n>queue_over_max_length_for_worker_1</span> <span class=o>=</span> <span class=kc>True</span>
        <span class=k>if</span> <span class=n>queue_over_max_length_for_worker_1</span><span class=p>:</span>
            <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>"The DB queue is above </span><span class=si>%s</span><span class=s2> pausing for 15 seconds."</span><span class=p>,</span> <span class=n>message_queue_max</span><span class=p>)</span>
            <span class=n>sleep</span><span class=p>(</span><span class=mi>15</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>break</span>
<span class=k>except</span> <span class=n>kombu</span><span class=o>.</span><span class=n>exceptions</span><span class=o>.</span><span class=n>OperationalError</span><span class=p>:</span>
    <span class=n>msg</span> <span class=o>=</span> <span class=s2>"Failed to connect to Celery Workers or to RabbitMQ at </span><span class=si>{}</span><span class=s2>"</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>celery_config</span><span class=o>.</span><span class=n>broker_url</span><span class=p>)</span>
    <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=n>msg</span><span class=p>)</span>
    <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=n>msg</span><span class=p>)</span>
</code></pre></div></table></div><h2>2. Setting appropriate task settings for this type of <span class=caps>DB</span> task</h2><p>In order to better manage this type of task, I set three of Celery’s Task setting. The results are ignored from the task, the task was configured for only acknowledged late rather than using the default of acknowledge on receipt rather than completion of the task (acks_late), and finally the time limits for this task was removed. The task is also configured to make two retry attempts if it fails.<div class=highlight><pre><span></span><code><span class=n>max_retries</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>ignore_result</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>acks_late</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>soft_time_limit</span><span class=o>=</span><span class=kc>None</span>
</code></pre></div><h2>3. Changing the database usage from a upsert to a insert and ignore approach</h2><p>This step actually removed the need for the backoff for my particular usage where a large number of upserts operations (updates for existing documents or if not present then the document(s) are inserted) were the root cause of the Celery Worker having such a long queue. A change to a insert only approach, which was feasible for my application as it only required the document to be present once, provided close on two orders of magnitute improvement to the database operations and significantly reduced the Celery Worker queue as tasks were no longer backing up.<div class=highlight><pre><span></span><code><span class=n>bulk_result</span> <span class=o>=</span> <span class=n>MongoClient</span><span class=p>(</span><span class=n>mongo_uri</span><span class=p>)</span><span class=o>.</span><span class=n>DATABASE</span><span class=o>.</span><span class=n>COLLECTION</span><span class=o>.</span><span class=n>bulk_write</span><span class=p>(</span><span class=n>array_of_insert_one_operations</span><span class=p>,</span> <span class=n>ordered</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</code></pre></div><h2>4. Minor discoveries in a useful practical sense but not core to solving my problem</h2><p>In the reading and research to address my queue growing too large and triggering the <a href=https://linux-mm.org/OOM_Killer>Linux out of memory (<span class=caps>OOM</span>) killer</a>, I found two useful Celery setting which I had not been aware of. Firstly, you can setup Celery Workers to receive events using the (“-E”) option which allows for restarting worker pools directly through Celery Flower (the Management <span class=caps>UI</span> I use for Celery) when combined with the “worker_pool_restarts” setting.<p>A second aspect of our internal tooling using a scraper approach, specifically a number of the workers use tasks that are primarily focused on asychronous <span class=caps>HTTP</span> requests so these use the <a href=http://docs.celeryproject.org/en/latest/userguide/concurrency/eventlet.html>Eventlet execution pool</a>. The deployment uses a standard Celery/RabbitMQ configuration. RabbitMQ uses a default setting where 10 concurrent connections are kept open for the broker pool when used with Celery. The setting “broker_pool_limit” allows for this to be raised, in this example below it is set to 100 which is more suitable for this type of Celery Worker/Eventlet execution pool combination.<div class=highlight><pre><span></span><code><span class=n>worker_pool_restarts</span> <span class=o>=</span> <span class=kc>True</span>
<span class=n>broker_pool_limit</span> <span class=o>=</span> <span class=mi>100</span>
</code></pre></div><h2>Future directions</h2><p>The tooling currently uses <a href=http://docs.celeryproject.org/en/latest/reference/celery.bin.multi.html>celery.bin.multi</a> with bash scripting as each node hosts multiple workers, however it is being containerized so I think my next blog will cover moving to <a href=http://supervisord.org/>supervisord</a> with a Celery setup of multiple workers per node providing multiple queues.</div></div></div><div class=container><div class=span3>Related Posts</div><div class=span6><ul><li><a href=http://eoinbrazil.com/queuesandworkflows.html>Two approaches to scale your processing: Task Queues and Workflows</a><li><a href=http://eoinbrazil.com/threepillarsofobservability.html>Add the three pillars of Observability to your Python App</a><li><a href=http://eoinbrazil.com/gradientboostingwithpython.html>An introduction to Gradient Boosting</a><li><a href=http://eoinbrazil.com/datapipelineswithpythonandmongodb.html>Data Pipelines with Python and MongoDB</a></ul></div></div></div><div class=container><div class=span3></div><div class=span6>Previous [ <a href=http://eoinbrazil.com/queuesandworkflows.html> Two approaches to scale your processing: Task Queues and Workflows </a> ] <br> Next [ <a href=http://eoinbrazil.com/threepillarsofobservability.html> Add the three pillars of Observability to your Python App </a> ]</div></div><div class=container><div class=span3> </div><div class=span6 id=post-share-links>Share via: <a title="Share on Twitter" href=https://twitter.com/intent/tweet?text=Celery%20Database%C2%A0Bottlenecks&url=http%3A//eoinbrazil.com/celerydatabasebottlenecks.html&via=eoinbrazil&hashtags=python,queues,celery,bottlenecks target=_blank><span class=symbol></span></a><a title="Share on Facebook" href=https://www.facebook.com/sharer/sharer.php?u=http%3A//eoinbrazil.com/celerydatabasebottlenecks.html target=_blank><span class=symbol></span></a><a title="Share on LinkedIn" href=https://www.linkedin.com/shareArticle?mini=true&url=http%3A//eoinbrazil.com/celerydatabasebottlenecks.html&title=Celery%20Database%C2%A0Bottlenecks&summary=I%20recently%20had%20to%20refactor%20some%20code%20which%20uses%20MongoDB%20and%20Celery%20to%20store%20results%20from%20a%20scraping%20process%20to%20a%20MongoDB%20collection.%20It%20involved%20a%20number%20of%20whack%20a%20mole%20type%20performance%20problems%20due%20to%20the%20distributed%20nature%20of%20the%20system%2C%20and%20indeed%20was%20leading%20to%20the%20Linux%20out%20%E2%80%A6&source=http%3A//eoinbrazil.com/celerydatabasebottlenecks.html target=_blank><span class=symbol></span></a><a title="Share on Google Plus" href target=_blank><span class=symbol></span></a><a title="Share via Email" href=mailto:?subject=Celery%20Database%C2%A0Bottlenecks&body=http%3A//eoinbrazil.com/celerydatabasebottlenecks.html target=_blank><span class=symbol></span></a> Feed Subscription via: <a title="RSS Feed" href=http://eoinbrazil.com/feeds/all.rss.xml target=_blank><span class=symbol></span></a><a title="ATOM Feed" href=http://eoinbrazil.com/feeds/all.atom.xml target=_blank><span class=symbol></span></a></div></div><div class=container><div class="row comments"><div class=span3> </div><div class=span6></div></div></div><div class=footer><div class=container><div class=row><div class=span6><p><strong>Eoin Brazil</strong> is a computer scientist, UX architect, technical services engineer (similar to SRE), author, teacher and data scientist. He has worked in various technical, leadership and educational roles within MongoDB Engineering. He currently works in the MongoDB Education team.A range of his work can be found on <a href=https://github.com/braz>Github</a>. Information on his co-authored book <a href=https://mongodbbook.info>MongoDB: The Definitive Guide 3rd edition from O'Reilly</a>. You can find his <a href=https://slideshare.net/eoinbrazil>talks</a> online as well as his <a href=http://eoinbrazil.com/pdfs/vitae-eoinbrazil-feb-2019-dev.pdf>CV</a>.</div><div class=span4><p><strong>Connect</strong><ul class=socialLinks><li><a href=http://www.twitter.com/eoinbrazil><span class=symbol></span> Twitter</a><li><a href=http://ie.linkedin.com/in/eoinbrazil><span class=symbol></span> LinkedIn</a><li><a href=https://foursquare.com/eoinbrazil><span class=symbol></span> Foursquare</a><li><a href=http://www.github.com/braz><span class=symbol></span> GitHub</a><li><a href=http://eoinbrazil.com/feeds/all.rss.xml><span class=symbol></span> RSS</a><li><a href=http://eoinbrazil.com/feeds/all.atom.xml><span class=symbol></span> ATOM</a></ul></div></div></div></div><script src=http://code.jquery.com/jquery.js></script><script src=http://eoinbrazil.com/theme/js/bootstrap.min.js></script>